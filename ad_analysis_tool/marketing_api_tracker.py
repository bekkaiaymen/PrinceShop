"""
Ù…ØªØªØ¨Ø¹ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Facebook Marketing API
Ø£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø­Ø©!
"""

import requests
import json
import pandas as pd
from datetime import datetime, timedelta
import time
from typing import List, Dict
import os
from dotenv import load_dotenv

load_dotenv()


class MarketingAPITracker:
    """Ù…ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Marketing API Ùˆ Ads Library"""
    
    def __init__(self, access_token: str, success_ratio: float = 0.1):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ØªØªØ¨Ø¹
        
        Args:
            access_token: Facebook Access Token
            success_ratio: Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ (Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ 0.1 = 10%)
        """
        self.access_token = access_token
        self.success_ratio = success_ratio
        self.base_url = "https://graph.facebook.com/v18.0"
        self.results = []
    
    def check_success(self, likes: int, comments: int) -> bool:
        """ÙØ­Øµ Ù†Ø¬Ø§Ø­ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†"""
        if likes == 0:
            return False
        required_comments = likes * self.success_ratio
        return comments >= required_comments
    
    def search_ads_library(self, search_terms: str, country: str = "US", 
                          limit: int = 50) -> List[Dict]:
        """
        Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª (Meta Ads Library API)
        
        Args:
            search_terms: ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«
            country: Ø§Ù„Ø¯ÙˆÙ„Ø© (US, UK, AE, SA, etc)
            limit: Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª
            
        Returns:
            Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª
        """
        print(f"\nğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª: {search_terms}")
        print(f"ğŸŒ Ø§Ù„Ø¯ÙˆÙ„Ø©: {country}")
        
        url = f"{self.base_url}/ads_archive"
        params = {
            'access_token': self.access_token,
            'search_terms': search_terms,
            'ad_reached_countries': country,
            'ad_active_status': 'ACTIVE',  # ÙÙ‚Ø· Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©
            'fields': 'id,ad_creative_body,ad_creative_link_caption,ad_delivery_start_time,ad_snapshot_url,page_name,page_id,impressions,spend',
            'limit': limit
        }
        
        try:
            response = requests.get(url, params=params, timeout=20)
            
            if response.status_code != 200:
                error = response.json().get('error', {})
                print(f"âŒ Ø®Ø·Ø£: {error.get('message', 'Unknown')}")
                
                # Ù†ØµÙŠØ­Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
                if 'permissions' in error.get('message', '').lower():
                    print("ğŸ’¡ ØªØ­ØªØ§Ø¬ ØµÙ„Ø§Ø­ÙŠØ© 'ads_read' - Ø±Ø§Ø¬Ø¹ BUSINESS_API_GUIDE.md")
                
                return []
            
            data = response.json()
            ads = data.get('data', [])
            
            print(f"âœ… ÙˆØ¬Ø¯Ù†Ø§ {len(ads)} Ø¥Ø¹Ù„Ø§Ù† Ù†Ø´Ø·")
            
            return ads
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£: {str(e)}")
            return []
    
    def get_ad_engagement(self, ad_data: Dict) -> Dict:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙØ§Ø¹Ù„ Ø¥Ø¹Ù„Ø§Ù† Ù…Ø­Ø¯Ø¯
        
        Args:
            ad_data: Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ù…Ù† Ads Library
            
        Returns:
            Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„
        """
        page_id = ad_data.get('page_id')
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Post ID (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹)
        # Ù…Ù„Ø§Ø­Ø¸Ø©: Ads Library Ù„Ø§ ÙŠÙˆÙØ± Post ID Ù…Ø¨Ø§Ø´Ø±Ø©
        # Ù†Ø­ØªØ§Ø¬ Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ù†Ø´ÙˆØ±Ø§Øª Ø§Ù„ØµÙØ­Ø©
        
        if not page_id:
            return {
                'likes': 0,
                'comments': 0,
                'shares': 0,
                'engagement_available': False
            }
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø­Ø¯Ø« Ù…Ù†Ø´ÙˆØ±Ø§Øª Ø§Ù„ØµÙØ­Ø©
        url = f"{self.base_url}/{page_id}/posts"
        params = {
            'access_token': self.access_token,
            'fields': 'message,likes.summary(true),comments.summary(true),shares,created_time',
            'limit': 10
        }
        
        try:
            response = requests.get(url, params=params, timeout=15)
            
            if response.status_code == 200:
                posts_data = response.json()
                posts = posts_data.get('data', [])
                
                # Ø§Ø¨Ø­Ø« Ø¹Ù† Ù…Ù†Ø´ÙˆØ± ÙŠØ·Ø§Ø¨Ù‚ Ù†Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†
                ad_body = ad_data.get('ad_creative_body', '')
                
                for post in posts:
                    post_message = post.get('message', '')
                    
                    # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¨Ø³ÙŠØ·Ø© (ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ†Ù‡Ø§)
                    if ad_body and ad_body[:50] in post_message:
                        return {
                            'likes': post.get('likes', {}).get('summary', {}).get('total_count', 0),
                            'comments': post.get('comments', {}).get('summary', {}).get('total_count', 0),
                            'shares': post.get('shares', {}).get('count', 0),
                            'engagement_available': True,
                            'post_id': post.get('id')
                        }
                
                # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ù…Ø·Ø§Ø¨Ù‚Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø­Ø¯Ø« Ù…Ù†Ø´ÙˆØ±
                if posts:
                    latest = posts[0]
                    return {
                        'likes': latest.get('likes', {}).get('summary', {}).get('total_count', 0),
                        'comments': latest.get('comments', {}).get('summary', {}).get('total_count', 0),
                        'shares': latest.get('shares', {}).get('count', 0),
                        'engagement_available': True,
                        'estimated': True
                    }
            
            return {
                'likes': 0,
                'comments': 0,
                'shares': 0,
                'engagement_available': False
            }
            
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ engagement: {str(e)}")
            return {
                'likes': 0,
                'comments': 0,
                'shares': 0,
                'engagement_available': False
            }
    
    def analyze_ads(self, search_terms: str, country: str = "US", 
                    limit: int = 50, get_engagement: bool = True):
        """
        ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª
        
        Args:
            search_terms: ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«
            country: Ø§Ù„Ø¯ÙˆÙ„Ø©
            limit: Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª
            get_engagement: Ù‡Ù„ Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§Ø¹Ù„ (ÙŠØ³ØªØºØ±Ù‚ ÙˆÙ‚Øª)
        """
        print("\n" + "="*60)
        print(f"ğŸš€ ØªØ­Ù„ÙŠÙ„ Ø¥Ø¹Ù„Ø§Ù†Ø§Øª: {search_terms}")
        print("="*60)
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª
        ads = self.search_ads_library(search_terms, country, limit)
        
        if not ads:
            print("âš ï¸ Ù„Ù… Ù†Ø¬Ø¯ Ø¥Ø¹Ù„Ø§Ù†Ø§Øª")
            return
        
        successful_ads = []
        
        for idx, ad in enumerate(ads, 1):
            print(f"\n[{idx}/{len(ads)}] Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¥Ø¹Ù„Ø§Ù†...")
            
            ad_id = ad.get('id')
            page_name = ad.get('page_name', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')
            ad_body = ad.get('ad_creative_body', '')[:100]
            start_date = ad.get('ad_delivery_start_time', '')
            snapshot_url = ad.get('ad_snapshot_url', '')
            
            # Ø­Ø³Ø§Ø¨ Ù…Ø¯Ø© Ù†Ø´Ø§Ø· Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† (Ù…Ø¤Ø´Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¬Ø§Ø­)
            days_active = 0
            if start_date:
                try:
                    start = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
                    days_active = (datetime.now(start.tzinfo) - start).days
                except:
                    pass
            
            # Ø§Ù„ØªÙØ§Ø¹Ù„
            engagement = {'likes': 0, 'comments': 0, 'shares': 0, 'engagement_available': False}
            
            if get_engagement:
                print(f"   â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§Ø¹Ù„...")
                engagement = self.get_ad_engagement(ad)
                time.sleep(1)  # ØªØ¬Ù†Ø¨ Rate Limit
            
            likes = engagement.get('likes', 0)
            comments = engagement.get('comments', 0)
            shares = engagement.get('shares', 0)
            
            # ÙØ­Øµ Ø§Ù„Ù†Ø¬Ø§Ø­
            is_successful = False
            success_score = 0
            
            if engagement.get('engagement_available'):
                is_successful = self.check_success(likes, comments)
                success_score = (comments / likes * 100) if likes > 0 else 0
            
            # Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø© Ù„ÙØªØ±Ø© Ø·ÙˆÙŠÙ„Ø© = Ù†Ø§Ø¬Ø­Ø© Ø¹Ø§Ø¯Ø©Ù‹
            long_running = days_active > 30
            
            ad_result = {
                'ad_id': ad_id,
                'page_name': page_name,
                'ad_body': ad_body,
                'start_date': start_date,
                'days_active': days_active,
                'long_running': long_running,
                'snapshot_url': snapshot_url,
                'likes': likes,
                'comments': comments,
                'shares': shares,
                'engagement_available': engagement.get('engagement_available', False),
                'is_successful': is_successful,
                'success_score': success_score,
                'timestamp': datetime.now().isoformat()
            }
            
            self.results.append(ad_result)
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
            print(f"   ğŸ“„ {page_name}")
            print(f"   ğŸ“ {ad_body[:60]}...")
            print(f"   â° Ù†Ø´Ø· Ù…Ù†Ø° {days_active} ÙŠÙˆÙ…")
            
            if engagement.get('engagement_available'):
                print(f"   ğŸ‘ {likes:,} | ğŸ’¬ {comments:,} | ğŸ”„ {shares:,}")
                print(f"   ğŸ“Š Ø§Ù„Ù†Ø³Ø¨Ø©: {success_score:.1f}%")
                
                if is_successful:
                    print(f"   âœ… Ø¥Ø¹Ù„Ø§Ù† Ù†Ø§Ø¬Ø­!")
                    successful_ads.append(ad_result)
            else:
                if long_running:
                    print(f"   â­ Ø¥Ø¹Ù„Ø§Ù† Ø·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ù‰ (Ù…Ø¤Ø´Ø± Ø¥ÙŠØ¬Ø§Ø¨ÙŠ)")
            
            print(f"   ğŸ”— {snapshot_url}")
        
        print(f"\nğŸ‰ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª: {len(ads)}")
        print(f"   Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {len(successful_ads)}")
        print(f"   Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰: {sum(1 for a in self.results if a['long_running'])}")
    
    def get_trending_searches(self) -> List[str]:
        """Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ø­Ø« Ø±Ø§Ø¨Ø­Ø©"""
        return [
            "dropshipping products",
            "trending products 2026",
            "viral products",
            "winning products",
            "best selling products",
            "ecommerce products",
            "print on demand",
            "tiktok viral products",
            "amazon fba products"
        ]
    
    def save_results(self, filename: str = "marketing_api_results.csv"):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        if not self.results:
            print("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ø­ÙØ¸Ù‡Ø§")
            return
        
        df = pd.DataFrame(self.results)
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø¹Ø¯Ø© Ù…Ø¹Ø§ÙŠÙŠØ±
        df = df.sort_values(['is_successful', 'long_running', 'success_score'], 
                           ascending=[False, False, False])
        
        # Ø­ÙØ¸ CSV
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"\nâœ… ØªÙ… Ø­ÙØ¸ {len(self.results)} Ù†ØªÙŠØ¬Ø© ÙÙŠ {filename}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ø§Ø¬Ø­Ø© ÙÙ‚Ø·
        successful = df[df['is_successful'] == True]
        if len(successful) > 0:
            successful.to_csv(f"winners_{filename}", index=False, encoding='utf-8-sig')
            print(f"â­ ØªÙ… Ø­ÙØ¸ {len(successful)} Ø¥Ø¹Ù„Ø§Ù† Ù†Ø§Ø¬Ø­ ÙÙŠ winners_{filename}")
        
        # Ø­ÙØ¸ Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰
        long_running = df[df['long_running'] == True]
        if len(long_running) > 0:
            long_running.to_csv(f"long_running_{filename}", index=False, encoding='utf-8-sig')
            print(f"ğŸ• ØªÙ… Ø­ÙØ¸ {len(long_running)} Ø¥Ø¹Ù„Ø§Ù† Ø·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ù‰ ÙÙŠ long_running_{filename}")
        
        return df
    
    def generate_report(self):
        """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± ØªÙØµÙŠÙ„ÙŠ"""
        if not self.results:
            print("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬")
            return
        
        df = pd.DataFrame(self.results)
        successful = df[df['is_successful'] == True]
        long_running = df[df['long_running'] == True]
        
        print("\n" + "="*60)
        print("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Marketing API")
        print("="*60)
        print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª: {len(self.results)}")
        print(f"Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {len(successful)} ({len(successful)/len(self.results)*100:.1f}%)")
        print(f"Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰ (>30 ÙŠÙˆÙ…): {len(long_running)} ({len(long_running)/len(self.results)*100:.1f}%)")
        print(f"Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ù†Ø¬Ø§Ø­: Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª >= {self.success_ratio*100}% Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø¨Ø§Øª")
        
        if len(successful) > 0:
            print(f"\nğŸ† Ø£ÙØ¶Ù„ 5 Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ù†Ø§Ø¬Ø­Ø©:")
            top_5 = successful.nlargest(5, 'success_score')
            for idx, row in enumerate(top_5.itertuples(), 1):
                print(f"\n{idx}. {row.page_name}")
                print(f"   ğŸ“Š Ø§Ù„Ù†Ø³Ø¨Ø©: {row.success_score:.1f}%")
                print(f"   ğŸ‘ {row.likes:,} | ğŸ’¬ {row.comments:,} | ğŸ”„ {row.shares:,}")
                print(f"   â° Ù†Ø´Ø· Ù…Ù†Ø° {row.days_active} ÙŠÙˆÙ…")
                print(f"   ğŸ“ {row.ad_body[:60]}...")
                print(f"   ğŸ”— {row.snapshot_url}")
        
        if len(long_running) > 0:
            print(f"\nâ° Ø£ÙØ¶Ù„ 5 Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø·ÙˆÙŠÙ„Ø© Ø§Ù„Ù…Ø¯Ù‰:")
            top_long = long_running.nlargest(5, 'days_active')
            for idx, row in enumerate(top_long.itertuples(), 1):
                print(f"\n{idx}. {row.page_name} - Ù†Ø´Ø· Ù…Ù†Ø° {row.days_active} ÙŠÙˆÙ…")
                print(f"   ğŸ“ {row.ad_body[:60]}...")
        
        print("="*60 + "\n")


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("="*60)
    print("ğŸš€ Ù…ØªØªØ¨Ø¹ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª - Marketing API")
    print("="*60)
    
    # Ù‚Ø±Ø§Ø¡Ø© Access Token
    access_token = None
    
    try:
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
            access_token = config.get('facebook_access_token', '')
    except:
        pass
    
    if not access_token:
        access_token = os.getenv('FACEBOOK_ACCESS_TOKEN', '')
    
    if not access_token:
        print("\nâŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Access Token!")
        print("ğŸ“– Ø±Ø§Ø¬Ø¹ BUSINESS_API_GUIDE.md Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯")
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ØªØªØ¨Ø¹
    tracker = MarketingAPITracker(access_token, success_ratio=0.1)
    
    print("\nğŸ’¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø¨Ø­Ø«:")
    suggestions = tracker.get_trending_searches()
    for i, term in enumerate(suggestions[:5], 1):
        print(f"   {i}. {term}")
    
    print("\nØ§Ø®ØªØ± Ø§Ù„ÙˆØ¶Ø¹:")
    print("1. Ø¨Ø­Ø« Ù…Ø®ØµØµ")
    print("2. Ø¨Ø­Ø« Ù…ØªØ¹Ø¯Ø¯ (Ø¹Ø¯Ø© ÙƒÙ„Ù…Ø§Øª)")
    print("3. Ù…Ø³Ø­ Ø´Ø§Ù…Ù„ (Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª)")
    
    choice = input("\nØ§Ø®ØªÙŠØ§Ø±Ùƒ (1-3): ").strip()
    
    if choice == "1":
        search = input("\nÙƒÙ„Ù…Ø© Ø§Ù„Ø¨Ø­Ø«: ").strip()
        country = input("Ø§Ù„Ø¯ÙˆÙ„Ø© (US, UK, AE, SA) [Ø§ÙØªØ±Ø§Ø¶ÙŠ: US]: ").strip() or "US"
        
        if search:
            tracker.analyze_ads(search, country=country, limit=50, get_engagement=True)
            tracker.save_results(f"ads_{search.replace(' ', '_')}.csv")
            tracker.generate_report()
    
    elif choice == "2":
        print("\nØ£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø« (ÙˆØ§Ø­Ø¯Ø© ÙÙŠ ÙƒÙ„ Ø³Ø·Ø±).")
        print("Ø§Ø¶ØºØ· Enter Ù…Ø±ØªÙŠÙ† Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡:\n")
        
        searches = []
        while True:
            term = input().strip()
            if not term:
                break
            searches.append(term)
        
        country = input("\nØ§Ù„Ø¯ÙˆÙ„Ø© (US, UK, AE, SA) [Ø§ÙØªØ±Ø§Ø¶ÙŠ: US]: ").strip() or "US"
        
        for search in searches:
            print(f"\n{'='*60}")
            tracker.analyze_ads(search, country=country, limit=30, get_engagement=True)
            time.sleep(5)  # Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÙŠÙ† Ø§Ù„Ø¨Ø­ÙˆØ«
        
        tracker.save_results("multi_search_results.csv")
        tracker.generate_report()
    
    elif choice == "3":
        print("\nğŸš€ Ù…Ø³Ø­ Ø´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª...")
        country = input("Ø§Ù„Ø¯ÙˆÙ„Ø© (US, UK, AE, SA) [Ø§ÙØªØ±Ø§Ø¶ÙŠ: US]: ").strip() or "US"
        
        for term in tracker.get_trending_searches():
            print(f"\n{'='*60}")
            tracker.analyze_ads(term, country=country, limit=20, get_engagement=False)
            time.sleep(5)
        
        tracker.save_results("comprehensive_scan.csv")
        tracker.generate_report()
    
    print("\nâœ… ØªÙ…!")


if __name__ == "__main__":
    main()
