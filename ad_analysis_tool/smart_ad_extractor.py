#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø© - Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒÙŠ Ø°ÙƒÙŠ
ÙŠØ¨Ø­Ø« ÙÙŠ Ad Library ÙˆÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Ø§Ø¬Ø­Ø© ÙÙ‚Ø· Ø­Ø³Ø¨ Ù‚Ø§Ø¹Ø¯ØªÙƒ
"""

import sys
print("ğŸ”§ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª...", flush=True)

try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.common.keys import Keys
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    import time
    import re
    import csv
    import json
    from datetime import datetime
    print("âœ… ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„\n", flush=True)
except ImportError as e:
    print(f"âŒ Ø®Ø·Ø£: {e}", flush=True)
    sys.exit(1)


class SmartAdExtractor:
    """Ù…Ø³ØªØ®Ø±Ø¬ Ø°ÙƒÙŠ Ù„Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©"""
    
    def __init__(self, success_ratio=0.1):
        self.driver = None
        self.success_ratio = success_ratio
        self.successful_ads = []
        self.total_scanned = 0
    
    def setup_driver(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØµÙØ­ Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø®ÙÙŠØ©"""
        print("ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØµÙØ­...", flush=True)
        
        chrome_options = Options()
        chrome_options.add_experimental_option("detach", True)
        chrome_options.add_argument('--start-maximized')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--no-sandbox')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        
        # Ø¥Ø®ÙØ§Ø¡ Ø£Ù†Ù‡ bot
        self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': '''
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            '''
        })
        
        print("âœ… Ø¬Ø§Ù‡Ø²\n", flush=True)
    
    def parse_number(self, text):
        """ØªØ­ÙˆÙŠÙ„ Ù†Øµ Ø¥Ù„Ù‰ Ø±Ù‚Ù… (1.5K â†’ 1500)"""
        if not text:
            return 0
        
        text = str(text).strip().lower()
        text = text.replace(',', '').replace(' ', '').replace('\u202f', '')
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ù‚Ù…
        match = re.search(r'([\d.]+)\s*([kmØ£Ù„ÙÙ…Ù„ÙŠÙˆÙ†]*)', text)
        if not match:
            return 0
        
        number = float(match.group(1))
        multiplier = match.group(2)
        
        if 'k' in multiplier or 'Ø£Ù„Ù' in multiplier:
            number *= 1000
        elif 'm' in multiplier or 'Ù…Ù„ÙŠÙˆÙ†' in multiplier:
            number *= 1000000
        
        return int(number)
    
    def extract_numbers_smart(self, element):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¨Ø°ÙƒØ§Ø¡ Ù…Ù† Ø¹Ù†ØµØ±"""
        try:
            # Ø·Ø±ÙŠÙ‚Ø© 1: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† aria-label
            aria_label = element.get_attribute('aria-label')
            if aria_label:
                numbers = self._parse_aria_label(aria_label)
                if numbers['likes'] > 0 or numbers['comments'] > 0:
                    return numbers
            
            # Ø·Ø±ÙŠÙ‚Ø© 2: Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„
            full_text = element.text
            if full_text:
                return self._parse_text_patterns(full_text)
            
            # Ø·Ø±ÙŠÙ‚Ø© 3: Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ÙØ±Ø¹ÙŠØ©
            return self._parse_child_elements(element)
            
        except Exception as e:
            return {'likes': 0, 'comments': 0, 'shares': 0}
    
    def _parse_aria_label(self, aria_label):
        """ØªØ­Ù„ÙŠÙ„ aria-label Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…"""
        numbers = {'likes': 0, 'comments': 0, 'shares': 0}
        
        # Ø¨Ø­Ø« Ø¹Ù† patterns Ø´Ø§Ø¦Ø¹Ø©
        patterns = {
            'likes': [
                r'(\d+[KkMm]?)\s*(?:like|Ø¥Ø¹Ø¬Ø§Ø¨|Ø£Ø¹Ø¬Ø¨|reaction)',
                r'(?:like|Ø¥Ø¹Ø¬Ø§Ø¨).*?(\d+[KkMm]?)',
            ],
            'comments': [
                r'(\d+[KkMm]?)\s*(?:comment|ØªØ¹Ù„ÙŠÙ‚)',
                r'(?:comment|ØªØ¹Ù„ÙŠÙ‚).*?(\d+[KkMm]?)',
            ],
            'shares': [
                r'(\d+[KkMm]?)\s*(?:share|Ù…Ø´Ø§Ø±ÙƒØ©)',
                r'(?:share|Ù…Ø´Ø§Ø±ÙƒØ©).*?(\d+[KkMm]?)',
            ]
        }
        
        for key, pattern_list in patterns.items():
            for pattern in pattern_list:
                match = re.search(pattern, aria_label, re.IGNORECASE)
                if match:
                    numbers[key] = self.parse_number(match.group(1))
                    break
        
        return numbers
    
    def _parse_text_patterns(self, text):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…"""
        numbers = {'likes': 0, 'comments': 0, 'shares': 0}
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ù„Ø£Ø³Ø·Ø±
        lines = text.split('\n')
        
        for line in lines:
            line_lower = line.lower()
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù…Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
            if any(word in line_lower for word in ['like', 'Ø¥Ø¹Ø¬Ø§Ø¨', 'Ø£Ø¹Ø¬Ø¨', 'reaction']):
                num = self.parse_number(re.search(r'(\d+[KkMm]?)', line).group(1) if re.search(r'(\d+[KkMm]?)', line) else '0')
                numbers['likes'] = max(numbers['likes'], num)
            
            elif any(word in line_lower for word in ['comment', 'ØªØ¹Ù„ÙŠÙ‚']):
                num = self.parse_number(re.search(r'(\d+[KkMm]?)', line).group(1) if re.search(r'(\d+[KkMm]?)', line) else '0')
                numbers['comments'] = max(numbers['comments'], num)
            
            elif any(word in line_lower for word in ['share', 'Ù…Ø´Ø§Ø±ÙƒØ©']):
                num = self.parse_number(re.search(r'(\d+[KkMm]?)', line).group(1) if re.search(r'(\d+[KkMm]?)', line) else '0')
                numbers['shares'] = max(numbers['shares'], num)
        
        return numbers
    
    def _parse_child_elements(self, element):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ÙØ±Ø¹ÙŠØ©"""
        numbers = {'likes': 0, 'comments': 0, 'shares': 0}
        
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¹Ù†ØµØ±
            all_text = element.text
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… regex
            # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ù…Ø«Ù„: "1.2K likes", "50 comments", "100 shares"
            # ÙˆØ£ÙŠØ¶Ø§ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: "Ù¢ Ø£Ù„Ù Ø¥Ø¹Ø¬Ø§Ø¨", "Ù¥Ù  ØªØ¹Ù„ÙŠÙ‚"
            
            # Ù†Ù…Ø· Ù„Ù„Ø£Ø±Ù‚Ø§Ù… (ÙŠØ¯Ø¹Ù… K/M ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ©)
            num_pattern = r'(\d+(?:\.\d+)?[KkMmØ£Ù„ÙÙ…Ù„ÙŠÙˆÙ†]?)'
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù„Ø§ÙŠÙƒØ§Øª
            likes_match = re.search(fr'{num_pattern}\s*(?:like|likes|Ø¥Ø¹Ø¬Ø§Ø¨|Ø¥Ø¹Ø¬Ø§Ø¨Ø§Øª|Ø£Ø¹Ø¬Ø¨|reaction)', all_text, re.IGNORECASE)
            if likes_match:
                numbers['likes'] = self.parse_number(likes_match.group(1))
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª
            comments_match = re.search(fr'{num_pattern}\s*(?:comment|comments|ØªØ¹Ù„ÙŠÙ‚|ØªØ¹Ù„ÙŠÙ‚Ø§Øª)', all_text, re.IGNORECASE)
            if comments_match:
                numbers['comments'] = self.parse_number(comments_match.group(1))
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ§Øª
            shares_match = re.search(fr'{num_pattern}\s*(?:share|shares|Ù…Ø´Ø§Ø±ÙƒØ©|Ù…Ø´Ø§Ø±ÙƒØ§Øª)', all_text, re.IGNORECASE)
            if shares_match:
                numbers['shares'] = self.parse_number(shares_match.group(1))
                
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©ØŒ Ù†Ø­Ø§ÙˆÙ„ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù†Ø§ØµØ± Ù…Ø­Ø¯Ø¯Ø© Ù‚Ø¯ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
            # ÙÙŠ Ad Library Ø§Ù„Ø¬Ø¯ÙŠØ¯ØŒ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ØºØ§Ù„Ø¨Ø§ ØªÙƒÙˆÙ† ÙÙŠ spans Ø¯Ø§Ø®Ù„ footer
            if numbers['likes'] == 0 and numbers['comments'] == 0:
                spans = element.find_elements(By.TAG_NAME, "span")
                for span in spans:
                    text = span.text.strip()
                    if not text: continue
                    
                    # Ù‡Ù„ Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "Likes" Ø£Ùˆ "Comments"ØŸ
                    if re.search(r'(?:like|Ø¥Ø¹Ø¬Ø§Ø¨|Ø£Ø¹Ø¬Ø¨)', text, re.IGNORECASE):
                        num_match = re.search(r'(\d+(?:\.\d+)?[KkMm]?)', text)
                        if num_match:
                            numbers['likes'] = max(numbers['likes'], self.parse_number(num_match.group(1)))
                            
                    if re.search(r'(?:comment|ØªØ¹Ù„ÙŠÙ‚)', text, re.IGNORECASE):
                        num_match = re.search(r'(\d+(?:\.\d+)?[KkMm]?)', text)
                        if num_match:
                            numbers['comments'] = max(numbers['comments'], self.parse_number(num_match.group(1)))

        except Exception as e:
            # print(f"DEBUG: Error parsing child elements: {e}")
            pass
        
        return numbers
    
    def open_ad_library(self, search_term, country='DZ'):
        """ÙØªØ­ Ad Library"""
        from urllib.parse import quote
        
        print(f"ğŸŒ ÙØªØ­ Ad Library...", flush=True)
        print(f"ğŸ” Ø§Ù„Ø¨Ø­Ø«: {search_term}", flush=True)
        print(f"ğŸŒ Ø§Ù„Ø¯ÙˆÙ„Ø©: {country}\n", flush=True)
        
        encoded = quote(search_term)
        url = f"https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country={country}&q={encoded}&search_type=keyword_unordered&media_type=all"
        
        self.driver.get(url)
        print("â³ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„...", flush=True)
        time.sleep(8)  # Ø§Ù†ØªØ¸Ø§Ø± Ø£Ø·ÙˆÙ„ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªØ­Ù…ÙŠÙ„
    
    def scroll_and_extract(self, target_count=50, max_scrolls=30):
        """Ø§Ù„ØªÙ…Ø±ÙŠØ± ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª"""
        print("\n" + "="*70)
        print(f"ğŸ“Š Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ (Ø§Ù„Ù‡Ø¯Ù: {target_count} Ø¥Ø¹Ù„Ø§Ù†)")
        print("="*70 + "\n", flush=True)
        
        scroll_count = 0
        last_height = 0
        no_change_count = 0
        
        while self.total_scanned < target_count and scroll_count < max_scrolls:
            try:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª ÙÙŠ Ø§Ù„ØµÙØ­Ø©
                # Ad Library ÙŠØ³ØªØ®Ø¯Ù… div Ù…Ø¹ data-pagelet
                ad_containers = self.driver.find_elements(By.CSS_SELECTOR, '[data-pagelet*="search"], [role="article"], div[class*="x1yztbdb"]')
                
                print(f"ğŸ” Ù…Ø±Ø± #{scroll_count + 1}: ÙˆØ¬Ø¯ {len(ad_containers)} Ø¹Ù†ØµØ±", flush=True)
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙ‚Ø·
                for container in ad_containers[self.total_scanned:]:
                    if self.total_scanned >= target_count:
                        break
                    
                    try:
                        ad_data = self._extract_single_ad(container)
                        
                        if ad_data and (ad_data['likes'] > 0 or ad_data['comments'] > 0):
                            self.total_scanned += 1
                            
                            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø©
                            if ad_data['likes'] > 0:
                                ratio = (ad_data['comments'] / ad_data['likes'])
                            else:
                                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙˆÙ„Ø§ ÙŠÙˆØ¬Ø¯ Ù„Ø§ÙŠÙƒØ§Øª (Ù†Ø§Ø¯Ø±Ø© ÙˆÙ„ÙƒÙ† Ù…Ù…ÙƒÙ†Ø©)
                                ratio = 1.0 if ad_data['comments'] > 0 else 0
                            
                            is_successful = ratio >= self.success_ratio
                            
                            ad_data['ratio'] = ratio * 100
                            ad_data['is_successful'] = is_successful
                            
                            status_icon = "âœ…" if is_successful else "âš™ï¸"
                            print(f"{status_icon} [{self.total_scanned}] L:{ad_data['likes']} C:{ad_data['comments']} Ratio:{ratio*100:.1f}%", flush=True)

                            if is_successful:
                                self.successful_ads.append(ad_data)
                                print(f"   ğŸ‘ Ø¥Ø¹Ù„Ø§Ù† Ù†Ø§Ø¬Ø­! ØªÙ…Øª Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù‚Ø§Ø¦Ù…Ø©.", flush=True)
                                print(f"   ğŸ“„ {ad_data['text'][:100].replace(chr(10), ' ')}...", flush=True)
                            
                        # else:
                            # print(".", end="", flush=True) # Ù…Ø¤Ø´Ø± Ø¹Ù„Ù‰ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø³Ù„Ø¨ÙŠ
                    
                    except Exception as e:
                        if 'stale' not in str(e).lower():
                            pass
                            # print(f"âš ï¸ Ø®Ø·Ø£: {str(e)[:40]}", flush=True)
                        continue
                
                # Ø§Ù„ØªÙ…Ø±ÙŠØ±
                current_height = self.driver.execute_script("return document.body.scrollHeight")
                
                if current_height == last_height:
                    no_change_count += 1
                    if no_change_count >= 3:
                        print("\nâš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©", flush=True)
                        break
                else:
                    no_change_count = 0
                
                last_height = current_height
                self.driver.execute_script("window.scrollBy(0, 1000);")
                time.sleep(3)
                scroll_count += 1
                
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ…Ø±ÙŠØ±: {str(e)[:50]}", flush=True)
                scroll_count += 1
                time.sleep(2)
        
        print(f"\n{'='*70}")
        print(f"âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬!")
        print(f"ğŸ“Š ØªÙ… ÙØ­Øµ: {self.total_scanned} Ø¥Ø¹Ù„Ø§Ù†")
        print(f"âœ… Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {len(self.successful_ads)} ({len(self.successful_ads)/max(self.total_scanned,1)*100:.1f}%)")
        print(f"{'='*70}\n", flush=True)
    
    def _extract_single_ad(self, container):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¹Ù„Ø§Ù† ÙˆØ§Ø­Ø¯"""
        data = {
            'text': '',
            'likes': 0,
            'comments': 0,
            'shares': 0,
            'url': '',
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
        try:
            text_elem = container.find_element(By.CSS_SELECTOR, 'div[dir="auto"]')
            data['text'] = text_elem.text[:200]
        except:
            data['text'] = container.text[:200] if container.text else ''
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…
        numbers = self.extract_numbers_smart(container)
        data.update(numbers)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø§Ø¨Ø·
        try:
            links = container.find_elements(By.TAG_NAME, 'a')
            for link in links:
                href = link.get_attribute('href')
                if href and 'facebook.com' in href and 'ads/library' not in href:
                    data['url'] = href.split('?')[0]
                    break
        except:
            pass
        
        return data if data['likes'] > 0 else None
    
    def save_results(self, filename=None):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        if not self.successful_ads:
            print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ù†Ø§Ø¬Ø­Ø© Ù„Ù„Ø­ÙØ¸!\n", flush=True)
            return
        
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"successful_ads_{timestamp}.csv"
        
        with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
            fieldnames = ['text', 'likes', 'comments', 'ratio', 'url', 'timestamp']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            
            writer.writeheader()
            for ad in self.successful_ads:
                writer.writerow({
                    'text': ad.get('text', ''),
                    'likes': ad.get('likes', 0),
                    'comments': ad.get('comments', 0),
                    'ratio': f"{ad.get('ratio', 0):.2f}%",
                    'url': ad.get('url', ''),
                    'timestamp': ad.get('timestamp', '')
                })
        
        print(f"ğŸ’¾ ØªÙ… Ø§Ù„Ø­ÙØ¸: {filename}\n", flush=True)
    
    def close(self):
        """Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…ØªØµÙØ­"""
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass


def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    print("\n" + "="*70)
    print("ğŸ¯ Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø© - Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒÙŠ")
    print("="*70 + "\n", flush=True)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
    extractor = SmartAdExtractor(success_ratio=0.1)
    
    try:
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØµÙØ­
        extractor.setup_driver()
        
        # Ø·Ù„Ø¨ Ø§Ù„Ù…Ù†ØªØ¬
        search_term = input("ğŸ” Ù…Ø§ Ø§Ù„Ù…Ù†ØªØ¬ØŸ (Ù…Ø«Ø§Ù„: Ø³Ù…Ø§Ø¹Ø§Øª Ø¨Ù„ÙˆØªÙˆØ«): ").strip()
        if not search_term:
            print("âŒ Ù„Ù… ØªØ¯Ø®Ù„ Ù…Ù†ØªØ¬", flush=True)
            return
        
        # Ø·Ù„Ø¨ Ø§Ù„Ø¹Ø¯Ø¯
        count_input = input("ğŸ“Š ÙƒÙ… Ø¥Ø¹Ù„Ø§Ù† ØªØ±ÙŠØ¯ ÙØ­ØµØŸ (Ø§ÙØªØ±Ø§Ø¶ÙŠ 50): ").strip()
        target_count = int(count_input) if count_input.isdigit() else 50
        
        # ÙØªØ­ Ad Library
        extractor.open_ad_library(search_term, country='DZ')
        
        # Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
        extractor.scroll_and_extract(target_count=target_count)
        
        # Ø§Ù„Ø­ÙØ¸
        if extractor.successful_ads:
            extractor.save_results()
            
            print("="*70)
            print("ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
            print("="*70)
            print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ÙØ­ÙˆØµØ©: {extractor.total_scanned}")
            print(f"Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {len(extractor.successful_ads)}")
            print(f"Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {len(extractor.successful_ads)/max(extractor.total_scanned,1)*100:.1f}%")
            print("="*70 + "\n")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ØªÙ… Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù\n", flush=True)
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£: {str(e)}\n", flush=True)
        import traceback
        traceback.print_exc()
    finally:
        print("\nğŸ“Œ Ø§Ù„Ù…ØªØµÙØ­ Ø³ÙŠØ¨Ù‚Ù‰ Ù…ÙØªÙˆØ­Ø§Ù‹ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ©", flush=True)
        print("ÙŠÙ…ÙƒÙ†Ùƒ Ø¥ØºÙ„Ø§Ù‚Ù‡ ÙŠØ¯ÙˆÙŠØ§Ù‹\n")


if __name__ == "__main__":
    main()
